{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr+5EacWe3iItYrMgZyzH0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GizawAAiT/Deep-Learning/blob/main/DL_Lab_4_Gizaw_Dagne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "fxkOV8dAl4uo"
      },
      "outputs": [],
      "source": [
        "# Import pytorch\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating  Delse Layers (Class)"
      ],
      "metadata": {
        "id": "snUSNjBtmL_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "  def __init__(self, features = 0, neurons= 0):\n",
        "    self.features= features\n",
        "    self.neurons = neurons\n",
        "    self.weights = torch.rand(features, neurons)\n",
        "    self.bias = torch.rand(neurons)\n",
        "\n",
        "  # Do forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = inputs@self.weights + self.bias\n",
        "\n",
        "  # relu activation\n",
        "  def setReluActivation(self, x):\n",
        "    self.relu = torch.max(x, torch.tensor(0))\n",
        "\n",
        "  # sigmoid activation\n",
        "  def setSigmoidActivation(self, x):\n",
        "    self.sigmoid = 1/(1 + torch.exp(-x))\n",
        "\n",
        "  # softmax activation\n",
        "  def setSoftmaxActivation(self, x):\n",
        "    exp_values = torch.exp(x - torch.max(x, axis=1, keepdim=True).values)\n",
        "    # Normalize them for each sample\n",
        "    self.softmax = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "\n",
        "  def setLinearActivation(self, x):\n",
        "    self.linear = x\n",
        "\n",
        "  # categorical loss cross entropy C.L.C.E\n",
        "  def categoricalCrossentropy(self, y_true, y_pred):\n",
        "    samples = len(y_pred)\n",
        "    # Clip data to prevent division by 0\n",
        "    # Clip both sides to not drag mean towards any value\n",
        "    y_pred_clipped = torch.clip(y_pred, 1e-8, 1 - 1e-8)\n",
        "    # only if categorical labels\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "    # Mask values - only for one-hot encoded labels\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = torch.sum(y_pred_clipped * y_true, axis=1)\n",
        "    log_loss = -torch.log(correct_confidences)\n",
        "    data_loss = torch.mean(log_loss)\n",
        "    return data_loss\n",
        "\n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    predictions = torch.argmax(y_pred, axis=1)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    acc = torch.mean((predictions == y_true).float())\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "eryKwgbemUJT"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_layer = DenseLayer()\n",
        "\n",
        "# sample data to calculate loss and accuracy:\n",
        "softmax_outputs = torch.tensor([[0.7, 0.1, 0.2], [0.1, 0.5, 0.4],[0.02, 0.9, 0.08]])\n",
        "class_targets = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
        "\n",
        "loss = sample_layer.categoricalCrossentropy(class_targets, softmax_outputs)\n",
        "accuracy = sample_layer.accuracy(softmax_outputs, class_targets)\n",
        "print(f'Loss = {loss}\\nAccuracy = {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2X-4xNhqXMR",
        "outputId": "b3ca5aea-b45c-4a7f-e1a8-59a82c0dffe8"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 1.653948426246643\n",
            "Accuracy = 0.6666666865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1\n",
        "### Preparing Dataset\n"
      ],
      "metadata": {
        "id": "KiBo_lRgsoyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "R_nJq4KguRdZ"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset from scikit-learn\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n"
      ],
      "metadata": {
        "id": "Z7wIOiP0uZTj"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "6HGba2Y5u0OI"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Feature names:\", iris.feature_names)\n",
        "print(\"Class names:\", iris.target_names)\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5eW6-TKu7nt",
        "outputId": "55841697-36b8-4080-b3c0-94e240d8ec5b"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([150, 4])\n",
            "y shape: torch.Size([150])\n",
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Class names: ['setosa' 'versicolor' 'virginica']\n",
            "tensor([[5.0999999046, 3.5000000000, 1.3999999762, 0.2000000030],\n",
            "        [4.9000000954, 3.0000000000, 1.3999999762, 0.2000000030],\n",
            "        [4.6999998093, 3.2000000477, 1.2999999523, 0.2000000030],\n",
            "        [4.5999999046, 3.0999999046, 1.5000000000, 0.2000000030],\n",
            "        [5.0000000000, 3.5999999046, 1.3999999762, 0.2000000030]])\n",
            "tensor([0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel():\n",
        "\n",
        "  def __init__(self, num_of_features, num_of_class):\n",
        "    # creating the model\n",
        "    self.dense1 = DenseLayer(num_of_features,16)\n",
        "    self.dense2 = DenseLayer(16, 16)\n",
        "    self.output_layer = DenseLayer(16, num_of_class)\n",
        "\n",
        "  def model(self, X, y):\n",
        "    self.y = y\n",
        "    # forward pass\n",
        "    self.dense1.forward(X)\n",
        "    self.dense1.setReluActivation(self.dense1.output)\n",
        "    self.dense2.forward(self.dense1.relu)\n",
        "    self.dense2.setReluActivation(self.dense2.output)\n",
        "    self.output_layer.forward(self.dense2.relu)\n",
        "    self.output_layer.setSoftmaxActivation(self.output_layer.output)\n",
        "\n",
        "  def loss_and_accuracy(self):\n",
        "    self.loss = self.output_layer.categoricalCrossentropy(self.y, self.output_layer.softmax)\n",
        "    self.accuracy = self.output_layer.accuracy(self.output_layer.softmax, self.y)"
      ],
      "metadata": {
        "id": "p5psWLvwvJHU"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = ClassificationModel(4, 3)"
      ],
      "metadata": {
        "id": "Qh8CflMy6Rmj"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.model(X, y)\n",
        "test.loss_and_accuracy()\n",
        "\n",
        "print(f'''loss = {test.loss}\\nAccuracy = {test.accuracy}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEgGIYHi6fIc",
        "outputId": "8d888a46-87a7-437d-e67c-b27941c8f71d"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 12.280454635620117\n",
            "Accuracy = 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  How can we adjust the weights and biases to decrease the loss?\n",
        "\n",
        "\n",
        "\n",
        "### Option 1). Randomly changing the weights, checking the loss, and repeating this until the lowest loss found."
      ],
      "metadata": {
        "id": "KIFILUhk9fy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_iris = ClassificationModel(4, 3)\n",
        "torch.set_printoptions(precision=10)\n",
        "lowest_loss = torch.tensor(99999999)\n",
        "ln_rate = 0.02"
      ],
      "metadata": {
        "id": "mRcbHw7F90w5"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration in range(1000):\n",
        "\n",
        "  # Perform a forward pass\n",
        "  test_iris.model(X,y)\n",
        "  test_iris.loss_and_accuracy()\n",
        "  loss = test_iris.loss\n",
        "  accuracy = test_iris.accuracy\n",
        "\n",
        "  # If loss is smaller - print and save weights and biases aside\n",
        "  if loss < lowest_loss:\n",
        "    print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
        "    best_dense1_weights = test_iris.dense1.weights\n",
        "    best_dense1_biases = test_iris.dense1.bias\n",
        "    best_dense2_weights = test_iris.dense2.weights\n",
        "    best_dense2_biases = test_iris.dense2.bias\n",
        "    best_output_layer_weights = test_iris.output_layer.weights\n",
        "    best_output_layer_biases = test_iris.output_layer.bias\n",
        "    lowest_loss = loss\n",
        "\n",
        "  # Generate a new set of weights for iteration\n",
        "  test_iris.dense1.weights = ln_rate * torch.rand(4, 16)\n",
        "  test_iris.dense1.biases = ln_rate * torch.rand(1, 16)\n",
        "  test_iris.dense2.weights = ln_rate * torch.rand(16, 16)\n",
        "  test_iris.dense2.biases = ln_rate * torch.rand(1, 16)\n",
        "\n",
        "  test_iris.output_layer.weights = ln_rate * torch.rand(16, 3)\n",
        "  test_iris.output_layer.biases = ln_rate * torch.rand(1, 3)"
      ],
      "metadata": {
        "id": "Kc78P0ab9_Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51175db3-fa45-4480-b481-61ac661bea87"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New set of weights found, iteration: 0 loss: tensor(12.2804546356) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 1 loss: tensor(1.1324729919) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 2 loss: tensor(1.1310031414) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 4 loss: tensor(1.1292535067) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 6 loss: tensor(1.1283520460) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 9 loss: tensor(1.1278623343) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 10 loss: tensor(1.1272079945) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 14 loss: tensor(1.1271808147) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 25 loss: tensor(1.1250435114) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 58 loss: tensor(1.1245460510) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 74 loss: tensor(1.1245013475) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 179 loss: tensor(1.1231161356) acc: tensor(0.3333333433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss:', test_iris.loss)\n",
        "print(\"Accuracy:\", test_iris.accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdLl4VpcAHXb",
        "outputId": "22fbb3aa-1080-4fcf-b496-a545372d9486"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(1.1306099892)\n",
            "Accuracy: tensor(0.3333333433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 2:) Instead of setting parameters with randomly-chosen values each iteration, apply a fraction of these values to parameters."
      ],
      "metadata": {
        "id": "jYOxhdOWAMSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_iris = ClassificationModel(4, 3)\n",
        "lowest_loss = torch.tensor(99999999)\n",
        "lr_rate = 0.05"
      ],
      "metadata": {
        "id": "t9uNE0_LARHJ"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration in range(10000):\n",
        "\n",
        "  # Perform a forward pass\n",
        "  test_iris.model(X,y)\n",
        "  test_iris.loss_and_accuracy()\n",
        "  loss = test_iris.loss\n",
        "  accuracy = test_iris.accuracy\n",
        "\n",
        "  # If loss is smaller - print and save weights and biases aside\n",
        "  if loss < lowest_loss:\n",
        "    print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
        "    best_dense1_weights = test_iris.dense1.weights\n",
        "    best_dense1_biases = test_iris.dense1.bias\n",
        "    best_dense2_weights = test_iris.dense2.weights\n",
        "    best_dense2_biases = test_iris.dense2.bias\n",
        "    best_output_layer_weights = test_iris.output_layer.weights\n",
        "    best_output_layer_biases = test_iris.output_layer.bias\n",
        "    lowest_loss = loss\n",
        "\n",
        "  else:\n",
        "    test_iris.dense1.weights = best_dense1_weights\n",
        "    test_iris.dense1.biases = best_dense1_biases\n",
        "    test_iris.dense2.weights = best_dense2_weights\n",
        "    test_iris.dense2.biases = best_dense2_biases\n",
        "    test_iris.output_layer.weights = best_output_layer_weights\n",
        "    test_iris.output_layer.biases = best_output_layer_biases\n",
        "\n",
        "  # Generate a new set of weights for iteration\n",
        "  test_iris.dense1.weights += lr_rate * torch.rand(4, 16)\n",
        "  test_iris.dense1.bias += lr_rate * torch.rand(16)\n",
        "  test_iris.dense2.weights += lr_rate * torch.rand(16, 16)\n",
        "  test_iris.dense2.bias += lr_rate * torch.rand(16)\n",
        "  test_iris.output_layer.weights += lr_rate * torch.rand(16, 3)\n",
        "  test_iris.output_layer.bias += lr_rate * torch.rand(3)"
      ],
      "metadata": {
        "id": "gOt7QhiqAaBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6d91a8-8b34-4b0e-99b0-01d861e63628"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New set of weights found, iteration: 0 loss: tensor(12.2804546356) acc: tensor(0.3333333433)\n",
            "New set of weights found, iteration: 12 loss: tensor(6.7108340263) acc: tensor(0.0533333346)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 3:  using optimization\n",
        "(Assignment)\n",
        "\n",
        "**Forward and Backward propagation**\n",
        "\n",
        "*   Use 2 features in the input layer, 1 hidden layer with 4 neurons, and an output layer with 2 neurons.\n",
        "*   Use sigmoid activation in the hidden layer and linear activation in the output layer.\n",
        "*   Assume the task is regression task and use MSE for the loss function.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U2TkhqPeB49G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create sample dataset\n",
        "X = torch.rand(32, 2)-.5 #distribute the random values between (-0.5 and +0.5).\n"
      ],
      "metadata": {
        "id": "wSPKHFMwCGY3"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the hiddnel layer and the output layer.\n",
        "hidden_layer = DenseLayer(2, 4)\n",
        "output_layer = DenseLayer(4, 2)"
      ],
      "metadata": {
        "id": "RNKe20X_LUUw"
      },
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sample true value\n",
        "y_true = torch.rand(32, 2) # The output layer has 2 neurons."
      ],
      "metadata": {
        "id": "ymyv0zyjKHD_"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the forward pass\n",
        "def forward_pass(X):\n",
        "  hidden_layer.forward(X)\n",
        "  hidden_layer.setSigmoidActivation(hidden_layer.output)\n",
        "  output_layer.forward(hidden_layer.output)\n",
        "  output_layer.setLinearActivation(output_layer.output)\n",
        "  # print(f'linear : {output_layer.linear}')\n",
        "\n",
        "  return output_layer.linear\n"
      ],
      "metadata": {
        "id": "PU2NMntsMEuj"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIlm9C6xNXwG"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def back_prop(fp):\n",
        "    lr = torch.tensor(0.01)\n",
        "    # Assuming y is the target for the regression task\n",
        "    error = fp - y_true\n",
        "\n",
        "    # Backpropagation for the output layer\n",
        "    output_layer.weights -= lr * (hidden_layer.sigmoid.T @ error)\n",
        "    output_layer.bias -= lr * torch.sum(error, dim=0)\n",
        "\n",
        "    # Backpropagation for the hidden layer\n",
        "    hidden_error = (error @ output_layer.weights.T) * hidden_layer.sigmoid * (1 - hidden_layer.sigmoid)\n",
        "    hidden_layer.weights -= lr * (X.T @ hidden_error)\n",
        "    hidden_layer.bias -= lr * torch.sum(hidden_error, dim=0)"
      ],
      "metadata": {
        "id": "BOAwDR3E13Ye"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error_calculation(y_true, y_pred):\n",
        "  return torch.mean(0.5*(y_true - y_pred)**2)"
      ],
      "metadata": {
        "id": "GaOilreGQTUa"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 0.099"
      ],
      "metadata": {
        "id": "rV-VgXYXQc-S"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = forward_pass(X)\n",
        "err = error_calculation(y_true, y_pred)\n",
        "print(\"Initial loss:\", err)\n",
        "print(\"Initial prediction:\", y_pred)\n",
        "while err > loss:\n",
        "  back_prop(y_pred)\n",
        "  y_pred = forward_pass(X)\n",
        "  err = error_calculation(y_true, y_pred)\n",
        "print(\"\\n\\n\\nFinal loss:\", err)\n",
        "print(\"Final prediction:\",y_pred)\n",
        "print(\"Target value:\",y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xif4ZvRoQfix",
        "outputId": "20eab4b5-9fe9-40e8-b54c-7c4a167f2598"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: tensor(0.7880818844)\n",
            "Initial prediction: tensor([[1.4152278900, 1.2860889435],\n",
            "        [1.7212860584, 1.4522829056],\n",
            "        [2.1913914680, 1.7633730173],\n",
            "        [1.6524333954, 1.4323304892],\n",
            "        [2.4005827904, 1.9116258621],\n",
            "        [1.2251117229, 1.1629550457],\n",
            "        [1.6194715500, 1.3856616020],\n",
            "        [1.7657186985, 1.4922084808],\n",
            "        [0.8690660596, 0.9686335921],\n",
            "        [2.0537621975, 1.6681077480],\n",
            "        [1.2621660233, 1.1773351431],\n",
            "        [2.0370202065, 1.6802566051],\n",
            "        [1.2974567413, 1.2299078703],\n",
            "        [2.1763648987, 1.7444640398],\n",
            "        [1.5875909328, 1.3703732491],\n",
            "        [0.9450339675, 1.0167793036],\n",
            "        [2.3470919132, 1.8322324753],\n",
            "        [1.5318077803, 1.3634107113],\n",
            "        [2.3729684353, 1.8826054335],\n",
            "        [1.4526010752, 1.3208800554],\n",
            "        [2.3735969067, 1.8725064993],\n",
            "        [1.8776748180, 1.5931897163],\n",
            "        [2.0083017349, 1.6729229689],\n",
            "        [2.5812366009, 1.9835014343],\n",
            "        [1.2393946648, 1.1823809147],\n",
            "        [1.2928119898, 1.1996594667],\n",
            "        [1.2939422131, 1.2223562002],\n",
            "        [2.3822195530, 1.8559896946],\n",
            "        [1.0625652075, 1.0510917902],\n",
            "        [1.8717414141, 1.5841608047],\n",
            "        [2.1852440834, 1.7505437136],\n",
            "        [2.1190314293, 1.7110406160]])\n",
            "\n",
            "\n",
            "\n",
            "Final loss: tensor(0.0950710922)\n",
            "Final prediction: tensor([[0.5963262320, 0.6226392388],\n",
            "        [0.7381482124, 0.6542840004],\n",
            "        [0.9936337471, 0.7897115946],\n",
            "        [0.7180030942, 0.6742858291],\n",
            "        [1.1139460802, 0.8652523160],\n",
            "        [0.4948089123, 0.5720310807],\n",
            "        [0.6833242178, 0.6261261702],\n",
            "        [0.7693929672, 0.6834516525],\n",
            "        [0.3291602731, 0.5336880088],\n",
            "        [0.9160113335, 0.7435464859],\n",
            "        [0.5081071258, 0.5669325590],\n",
            "        [0.9225792885, 0.7748538852],\n",
            "        [0.5469942093, 0.6225490570],\n",
            "        [0.9794204235, 0.7714374065],\n",
            "        [0.6699160337, 0.6259770989],\n",
            "        [0.3690123856, 0.5522662997],\n",
            "        [1.0552011728, 0.7814074755],\n",
            "        [0.6598017216, 0.6564965844],\n",
            "        [1.0916901827, 0.8405807614],\n",
            "        [0.6234222651, 0.6490531564],\n",
            "        [1.0849397182, 0.8244060278],\n",
            "        [0.8483772278, 0.7575382590],\n",
            "        [0.9148434401, 0.7847342491],\n",
            "        [1.1799716949, 0.8431430459],\n",
            "        [0.5092985630, 0.5916603804],\n",
            "        [0.5261411071, 0.5789412260],\n",
            "        [0.5415593386, 0.6134076715],\n",
            "        [1.0746369362, 0.7923229933],\n",
            "        [0.4035712779, 0.5185182095],\n",
            "        [0.8417110443, 0.7478921413],\n",
            "        [0.9843834639, 0.7743126154],\n",
            "        [0.9513082504, 0.7619464993]])\n",
            "Target value: tensor([[0.2704030871, 0.7035998106],\n",
            "        [0.8421358466, 0.8133365512],\n",
            "        [0.4330979586, 0.0917163491],\n",
            "        [0.1223080158, 0.2872374058],\n",
            "        [0.4985408783, 0.7728177309],\n",
            "        [0.0498858690, 0.0768449903],\n",
            "        [0.8557305336, 0.5088598132],\n",
            "        [0.5585815907, 0.2867730856],\n",
            "        [0.5173241496, 0.4214786887],\n",
            "        [0.2841449380, 0.0571053624],\n",
            "        [0.4539685845, 0.7472324371],\n",
            "        [0.0161847472, 0.5356156826],\n",
            "        [0.7057042122, 0.8182058334],\n",
            "        [0.8548537493, 0.3532164097],\n",
            "        [0.6420145035, 0.9300066829],\n",
            "        [0.9254162908, 0.8043615818],\n",
            "        [0.0031861067, 0.6669584513],\n",
            "        [0.1310502887, 0.6643469930],\n",
            "        [0.8734653592, 0.5835474133],\n",
            "        [0.5786195993, 0.2746909857],\n",
            "        [0.2757840157, 0.6728014350],\n",
            "        [0.2510421276, 0.2949206829],\n",
            "        [0.6174748540, 0.0471791625],\n",
            "        [0.3490576744, 0.0383378267],\n",
            "        [0.2264207006, 0.4058560133],\n",
            "        [0.6423962712, 0.5267152190],\n",
            "        [0.8753691912, 0.5559602976],\n",
            "        [0.4311903119, 0.9644445777],\n",
            "        [0.8373659849, 0.0185428858],\n",
            "        [0.7781618237, 0.0225299597],\n",
            "        [0.8187639713, 0.1820606589],\n",
            "        [0.5584775209, 0.6166693568]])\n"
          ]
        }
      ]
    }
  ]
}