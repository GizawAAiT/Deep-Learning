{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+gtZ6+ducV/xKPqItNsYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GizawAAiT/Deep-Learning/blob/main/DL_Lab_4_Gizaw_Dagne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fxkOV8dAl4uo"
      },
      "outputs": [],
      "source": [
        "# Import pytorch\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating  Delse Layers (Class)"
      ],
      "metadata": {
        "id": "snUSNjBtmL_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "  def __init__(self, features = 0, neurons= 0):\n",
        "    self.features= features\n",
        "    self.neurons = neurons\n",
        "    self.weights = torch.rand(features, neurons)\n",
        "    self.bias = torch.rand(neurons)\n",
        "\n",
        "  # Do forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = inputs@self.weights + self.bias\n",
        "\n",
        "  # relu activation\n",
        "  def setReluActivation(self, x):\n",
        "    self.relu = torch.max(x, torch.tensor(0))\n",
        "\n",
        "  # sigmoid activation\n",
        "  def setSigmoidActivation(self, x):\n",
        "    self.sigmoid = 1/(1 + torch.exp(-x))\n",
        "\n",
        "  # softmax activation\n",
        "  def setSoftmaxActivation(self, x):\n",
        "    exp_values = torch.exp(x - torch.max(x, axis=1, keepdim=True).values)\n",
        "    # Normalize them for each sample\n",
        "    self.softmax = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "\n",
        "  # categorical loss cross entropy C.L.C.E\n",
        "  def categoricalCrossentropy(self, y_true, y_pred):\n",
        "    samples = len(y_pred)\n",
        "    # Clip data to prevent division by 0\n",
        "    # Clip both sides to not drag mean towards any value\n",
        "    y_pred_clipped = torch.clip(y_pred, 1e-8, 1 - 1e-8)\n",
        "    # only if categorical labels\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "    # Mask values - only for one-hot encoded labels\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = torch.sum(y_pred_clipped * y_true, axis=1)\n",
        "    log_loss = -torch.log(correct_confidences)\n",
        "    data_loss = torch.mean(log_loss)\n",
        "    return data_loss\n",
        "\n",
        "  def accuracy(self, y_pred, y_true):\n",
        "    predictions = torch.argmax(y_pred, axis=1)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    acc = torch.mean((predictions == y_true).float())\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "eryKwgbemUJT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_layer = DenseLayer()\n",
        "\n",
        "# sample data to calculate loss and accuracy:\n",
        "softmax_outputs = torch.tensor([[0.7, 0.1, 0.2], [0.1, 0.5, 0.4],[0.02, 0.9, 0.08]])\n",
        "class_targets = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
        "\n",
        "loss = sample_layer.categoricalCrossentropy(class_targets, softmax_outputs)\n",
        "accuracy = sample_layer.accuracy(softmax_outputs, class_targets)\n",
        "print(f'Loss = {loss}\\nAccuracy = {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2X-4xNhqXMR",
        "outputId": "7b2e26cd-96af-40cc-f936-6580e4899da5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 1.653948426246643\n",
            "Accuracy = 0.6666666865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1\n",
        "### Preparing Dataset\n"
      ],
      "metadata": {
        "id": "KiBo_lRgsoyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "R_nJq4KguRdZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset from scikit-learn\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n"
      ],
      "metadata": {
        "id": "Z7wIOiP0uZTj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "6HGba2Y5u0OI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Feature names:\", iris.feature_names)\n",
        "print(\"Class names:\", iris.target_names)\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5eW6-TKu7nt",
        "outputId": "713ef121-33f0-4f20-9814-8a95451ea65a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([150, 4])\n",
            "y shape: torch.Size([150])\n",
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Class names: ['setosa' 'versicolor' 'virginica']\n",
            "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
            "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
            "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
            "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
            "        [5.0000, 3.6000, 1.4000, 0.2000]])\n",
            "tensor([0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel():\n",
        "\n",
        "  def __init__(self, num_of_features, num_of_class):\n",
        "    # creating the model\n",
        "    self.dense1 = DenseLayer(num_of_features,16)\n",
        "    self.dense2 = DenseLayer(16, 16)\n",
        "    self.output_layer = DenseLayer(16, num_of_class)\n",
        "\n",
        "  def model(self, X, y):\n",
        "    self.y = y\n",
        "    # forward pass\n",
        "    self.dense1.forward(X)\n",
        "    self.dense1.setReluActivation(self.dense1.output)\n",
        "    self.dense2.forward(self.dense1.relu)\n",
        "    self.dense2.setReluActivation(self.dense2.output)\n",
        "    self.output_layer.forward(self.dense2.relu)\n",
        "    self.output_layer.setSoftmaxActivation(self.output_layer.output)\n",
        "\n",
        "  def loss_and_accuracy(self):\n",
        "    self.loss = self.output_layer.categoricalCrossentropy(self.y, self.output_layer.softmax)\n",
        "    self.accuracy = self.output_layer.accuracy(self.output_layer.softmax, self.y)"
      ],
      "metadata": {
        "id": "p5psWLvwvJHU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = ClassificationModel(4, 3)"
      ],
      "metadata": {
        "id": "Qh8CflMy6Rmj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.model(X, y)\n",
        "test.loss_and_accuracy()\n",
        "\n",
        "print(f'''loss = {test.loss}\\nAccuracy = {test.accuracy}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEgGIYHi6fIc",
        "outputId": "5b9ccb66-9dc8-4252-f67b-c12c0e0236e4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 12.280454635620117\n",
            "Accuracy = 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  How can we adjust the weights and biases to decrease the loss?\n",
        "\n",
        "\n",
        "\n",
        "### Option 1). Randomly changing the weights, checking the loss, and repeating this until the lowest loss found."
      ],
      "metadata": {
        "id": "KIFILUhk9fy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_iris = ClassificationModel(4, 3)\n",
        "torch.set_printoptions(precision=10)\n",
        "lowest_loss = torch.tensor(99999999)\n",
        "ln_rate = 0.02"
      ],
      "metadata": {
        "id": "mRcbHw7F90w5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration in range(1000):\n",
        "\n",
        "  # Perform a forward pass\n",
        "  test_iris.model(X,y)\n",
        "  test_iris.loss_and_accuracy()\n",
        "  loss = test_iris.loss\n",
        "  accuracy = test_iris.accuracy\n",
        "\n",
        "  # If loss is smaller - print and save weights and biases aside\n",
        "  if loss < lowest_loss:\n",
        "    print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
        "    best_dense1_weights = test_iris.dense1.weights\n",
        "    best_dense1_biases = test_iris.dense1.bias\n",
        "    best_dense2_weights = test_iris.dense2.weights\n",
        "    best_dense2_biases = test_iris.dense2.bias\n",
        "    best_output_layer_weights = test_iris.output_layer.weights\n",
        "    best_output_layer_biases = test_iris.output_layer.bias\n",
        "    lowest_loss = loss\n",
        "\n",
        "  # Generate a new set of weights for iteration\n",
        "  test_iris.dense1.weights = ln_rate * torch.rand(4, 16)\n",
        "  test_iris.dense1.biases = ln_rate * torch.rand(1, 16)\n",
        "  test_iris.dense2.weights = ln_rate * torch.rand(16, 16)\n",
        "  test_iris.dense2.biases = ln_rate * torch.rand(1, 16)\n",
        "\n",
        "  test_iris.output_layer.weights = ln_rate * torch.rand(16, 3)\n",
        "  test_iris.output_layer.biases = ln_rate * torch.rand(1, 3)"
      ],
      "metadata": {
        "id": "Kc78P0ab9_Mb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss:', test_iris.loss)\n",
        "print(\"Accuracy:\", test_iris.accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdLl4VpcAHXb",
        "outputId": "4eadb0f3-9f1a-4dff-e8e4-a72fc1e7d5e8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(1.1332967281)\n",
            "Accuracy: tensor(0.3333333433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 2:) Instead of setting parameters with randomly-chosen values each iteration, apply a fraction of these values to parameters."
      ],
      "metadata": {
        "id": "jYOxhdOWAMSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_iris = ClassificationModel(4, 3)\n",
        "lowest_loss = torch.tensor(99999999)\n",
        "lr_rate = 0.04"
      ],
      "metadata": {
        "id": "t9uNE0_LARHJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration in range(100000):\n",
        "\n",
        "  # Perform a forward pass\n",
        "  test_iris.model(X,y)\n",
        "  test_iris.loss_and_accuracy()\n",
        "  loss = test_iris.loss\n",
        "  accuracy = test_iris.accuracy\n",
        "\n",
        "  # If loss is smaller - print and save weights and biases aside\n",
        "  if loss < lowest_loss:\n",
        "    print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n",
        "    best_dense1_weights = test_iris.dense1.weights\n",
        "    best_dense1_biases = test_iris.dense1.bias\n",
        "    best_dense2_weights = test_iris.dense2.weights\n",
        "    best_dense2_biases = test_iris.dense2.bias\n",
        "    best_output_layer_weights = test_iris.output_layer.weights\n",
        "    best_output_layer_biases = test_iris.output_layer.bias\n",
        "    lowest_loss = loss\n",
        "\n",
        "  else:\n",
        "    test_iris.dense1.weights = best_dense1_weights\n",
        "    test_iris.dense1.biases = best_dense1_biases\n",
        "    test_iris.dense2.weights = best_dense2_weights\n",
        "    test_iris.dense2.biases = best_dense2_biases\n",
        "    test_iris.output_layer.weights = best_output_layer_weights\n",
        "    test_iris.output_layer.biases = best_output_layer_biases\n",
        "\n",
        "  # Generate a new set of weights for iteration\n",
        "  test_iris.dense1.weights += lr_rate * torch.rand(4, 16)\n",
        "  test_iris.dense1.bias += lr_rate * torch.rand(16)\n",
        "  test_iris.dense2.weights += lr_rate * torch.rand(16, 16)\n",
        "  test_iris.dense2.bias += lr_rate * torch.rand(16)\n",
        "  test_iris.output_layer.weights += lr_rate * torch.rand(16, 3)\n",
        "  test_iris.output_layer.bias += lr_rate * torch.rand(3)"
      ],
      "metadata": {
        "id": "gOt7QhiqAaBj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option 3:  using optimization\n",
        "(Assignment)\n",
        "\n",
        "**Forward and Backward propagation**\n",
        "\n",
        "*   Use 2 features in the input layer, 1 hidden layer with 4 neurons, and an output layer with 2 neurons.\n",
        "*   Use sigmoid activation in the hidden layer and linear activation in the output layer.\n",
        "*   Assume the task is regression task and use MSE for the loss function.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U2TkhqPeB49G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create sample dataset\n",
        "X = torch.rand(32, 2)-.5 #distribute the random values between (-0.5 and +0.5).\n"
      ],
      "metadata": {
        "id": "wSPKHFMwCGY3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the hiddnel layer and the output layer.\n",
        "hidden_layer = DenseLayer(2, 4)\n",
        "output_layer = DenseLayer(4, 2)"
      ],
      "metadata": {
        "id": "RNKe20X_LUUw"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sample true value\n",
        "y_true = torch.zeros(32, 2) # The output layer has 2 neurons.\n",
        "indices = torch.arange(32) % 2\n",
        "y_true[torch.arange(32), indices] = 1\n"
      ],
      "metadata": {
        "id": "ymyv0zyjKHD_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the forward pass\n",
        "def forward_pass(X):\n",
        "  hidden_layer.forward(X)\n",
        "  hidden_layer.setSigmoidActivation(hidden_layer.output)\n",
        "  output_layer.forward(hidden_layer.output)\n",
        "  output_layer.setReluActivation(output_layer.output)\n",
        "  return output_layer.relu\n",
        ""
      ],
      "metadata": {
        "id": "PU2NMntsMEuj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_prop(fp):\n",
        "  lr = torch.tensor(0.01)\n",
        "  back1 = (fp[0][0]-y[0])*(1-fp[0][0])*fp[0][0]\n",
        "  back2 = (fp[0][1]-y[1])*(1-fp[0][1])*fp[0][1]\n",
        "  output_layer.weights[0][0] -= lr * back1*hidden_layer.sigmoid[0][0]\n",
        "  output_layer.weights[0][1] -= lr * back1*hidden_layer.sigmoid[0][1]\n",
        "  output_layer.weights[1][0] -= lr * back2*hidden_layer.sigmoid[0][0]\n",
        "  output_layer.weights[1][1] -= lr * back2*hidden_layer.sigmoid[0][1]\n",
        "  output_layer.bias[0][0] -= lr * back1\n",
        "  output_layer.bias[0][1] -= lr * back2\n",
        "\n",
        "  hidden_layer.weights[0][0] -= lr * (back1 * output_layer.weights[0][0] * X[0] + back2 * output_layer.weights[0][1] * X[0] ) if hidden_layer.output[0][0] > 0 else 0\n",
        "  hidden_layer.weights[0][1] -= lr * (back1 * output_layer.weights[0][0] * X[1] + back2 * output_layer.weights[0][1] * X[1] ) if hidden_layer.output[0][0] > 0 else 0\n",
        "  hidden_layer.weights[1][0] -= lr * (back1 * output_layer.weights[1][0] * X[0] + back2 * output_layer.weights[1][1] * X[0] ) if hidden_layer.output[0][1] > 0 else 0\n",
        "  hidden_layer.weights[1][1] -= lr * (back1 * output_layer.weights[1][0] * X[1] + back2 * output_layer.weights[1][1] * X[1] ) if hidden_layer.output[0][1] > 0 else 0\n",
        "  hidden_layer.biases[0][0] -=  lr * (back1 * output_layer.weights[0][0] + back2 * output_layer.weights[0][1] ) if hidden_layer.output[0][0] > 0 else 0\n",
        "  hidden_layer.biases[0][1] -=  lr * (back1 * output_layer.weights[1][0] + back2 * output_layer.weights[1][1] ) if hidden_layer.output[0][1] > 0 else 0\n"
      ],
      "metadata": {
        "id": "TIlm9C6xNXwG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def error_calculation(y_true, y_pred):\n",
        "  return torch.mean(0.5*(y_true - y_pred)**2)"
      ],
      "metadata": {
        "id": "GaOilreGQTUa"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 0.0001"
      ],
      "metadata": {
        "id": "rV-VgXYXQc-S"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = forward_pass(X)\n",
        "err = error_calculation(y_true, y_pred)\n",
        "print(\"Initial loss:\", err)\n",
        "print(\"Initial prediction:\",y_pred)\n",
        "while err > loss:\n",
        "  back_prop(y_pred)\n",
        "  y_pred = forward_pass(X)\n",
        "  err = error_calculation(y, y_pred)\n",
        "print(\"Final loss:\", err)\n",
        "print(\"Final prediction:\",y_pred)\n",
        "print(\"Target value:\",y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "xif4ZvRoQfix",
        "outputId": "339a2003-71d3-4638-8c5e-78ed8a4baa16"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: tensor(0.5806272030)\n",
            "Initial prediction: tensor([[1.7914195061, 1.6171853542],\n",
            "        [1.5626579523, 1.4109292030],\n",
            "        [1.2335898876, 1.1679762602],\n",
            "        [1.4405765533, 1.3233706951],\n",
            "        [1.4099265337, 1.3500325680],\n",
            "        [1.4258565903, 1.3487269878],\n",
            "        [1.5081071854, 1.4059038162],\n",
            "        [1.8774740696, 1.6763368845],\n",
            "        [1.7275390625, 1.6244031191],\n",
            "        [1.5574624538, 1.4846546650],\n",
            "        [1.4400131702, 1.3662666082],\n",
            "        [1.4230582714, 1.3830027580],\n",
            "        [1.4653320312, 1.4458963871],\n",
            "        [1.1319957972, 1.1586314440],\n",
            "        [1.3081954718, 1.3152841330],\n",
            "        [1.4058095217, 1.3304818869],\n",
            "        [1.4645537138, 1.3789458275],\n",
            "        [1.7161253691, 1.6086698771],\n",
            "        [1.1535162926, 1.1901698112],\n",
            "        [1.4821950197, 1.4271482229],\n",
            "        [1.7499983311, 1.5817646980],\n",
            "        [1.7842348814, 1.6153253317],\n",
            "        [1.8637571335, 1.6579051018],\n",
            "        [1.1503807306, 1.1458729506],\n",
            "        [1.0343202353, 1.0739167929],\n",
            "        [1.3350639343, 1.2470626831],\n",
            "        [1.7732820511, 1.6169569492],\n",
            "        [1.5589904785, 1.4256322384],\n",
            "        [1.2029689550, 1.2348483801],\n",
            "        [1.3469496965, 1.2658344507],\n",
            "        [1.3374593258, 1.2998927832],\n",
            "        [1.4214483500, 1.3265829086]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-6a78b7727b2d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_calculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-62a74c4d0e49>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(fp)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mback2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mback2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mback1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mback2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
          ]
        }
      ]
    }
  ]
}